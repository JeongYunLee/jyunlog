[{"data":1,"prerenderedAt":139},["Reactive",2],{"content-/blog/2023-12-12-usedcar-miniproject(2)":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":7,"_empty":6,"title":8,"description":7,"date":9,"tags":10,"draft":6,"summary":17,"body":18,"_type":134,"_id":135,"_source":136,"_file":137,"_extension":138},"/blog/2023-12-12-usedcar-miniproject(2)","blog",false,"","중고차 가격 예측 미니 프로젝트(2)","2023-12-12",[11,12,13,14,15,16],"miniproject","kaggle","ML","NLP","KMeans","SBERT","kaggle의 used car data를 활용한 mini proejct 관련한 두번째 글입니다. 모델 학습의 내용을 다룹니다.",{"type":19,"children":20,"toc":121},"root",[21,69,76,82,88,94,99,104,110,115],{"type":22,"tag":23,"props":24,"children":26},"element","div",{"style":25},"color:#F08080;border-radius:10px;text-align:center;",[27,30,45,46,57,58],{"type":28,"value":29},"text","\n    ",{"type":22,"tag":31,"props":32,"children":33},"h3",{},[34],{"type":22,"tag":35,"props":36,"children":37},"em",{},[38],{"type":22,"tag":39,"props":40,"children":42},"span",{"style":41},"color:#F08080;",[43],{"type":28,"value":44},"❝",{"type":28,"value":29},{"type":22,"tag":31,"props":47,"children":48},{},[49],{"type":22,"tag":35,"props":50,"children":51},{},[52],{"type":22,"tag":39,"props":53,"children":54},{"style":41},[55],{"type":28,"value":56},"작성 중인 문서입니다.",{"type":28,"value":29},{"type":22,"tag":31,"props":59,"children":60},{},[61],{"type":22,"tag":35,"props":62,"children":63},{},[64],{"type":22,"tag":39,"props":65,"children":66},{"style":41},[67],{"type":28,"value":68},"❞",{"type":22,"tag":70,"props":71,"children":73},"h2",{"id":72},"_2-regression",[74],{"type":28,"value":75},"2. Regression",{"type":22,"tag":70,"props":77,"children":79},{"id":78},"_3-clustering",[80],{"type":28,"value":81},"3. Clustering",{"type":22,"tag":31,"props":83,"children":85},{"id":84},"_3-1-기본-clusteinrg",[86],{"type":28,"value":87},"3-1. 기본 clusteinrg",{"type":22,"tag":89,"props":90,"children":91},"p",{},[92],{"type":28,"value":93},"처음에 생각한 것 처럼 적합, 부적합 labeling을 하기에는 또 다른 주관적인 노이즈를 만드는 것 같아서 (평균에서 몇%까지는 적합하다는 기준을 다시 주관적으로 부여해야 하기 때문에) 진행하지 않고, 최종 결과는 classification의 결과로 나온 그룹의 대표 feature 값들을 보여주는 방식으로 진행했습니다.",{"type":22,"tag":89,"props":95,"children":96},{},[97],{"type":28,"value":98},"clustering은 K-Means을 활용했습니다. K-Medoids와 DBSCAN도 시도했지만, 계산량이 너무 많거나 성능이 별로 좋지 않았습니다. clsutering과정에서 가장 애먹은 부분은 아무래도 적절한 K를 찾는 부분입니다. elbow method를 활용해봐도 적절한 elbow가 보이지 않고, silluette score를 계산해보면 K가 커질 수록 한없이 스코어가 높아졌습니다. 따라서 최대한 적합점을 찾은게 K=500이었으나, 사실 이 결론이 최선이었는지에 대한 확신은 없습니다..ㅎㅎ",{"type":22,"tag":89,"props":100,"children":101},{},[102],{"type":28,"value":103},"clustering 이후 각 feature들에",{"type":22,"tag":31,"props":105,"children":107},{"id":106},"_3-2-text-clustering",[108],{"type":28,"value":109},"3-2. Text clustering",{"type":22,"tag":89,"props":111,"children":112},{},[113],{"type":28,"value":114},"학습한 모델로 간단한 데모 제작과 관련된 내용은 다음 (3) 글에서 다룹니다~",{"type":22,"tag":70,"props":116,"children":118},{"id":117},"_4-classification",[119],{"type":28,"value":120},"4. Classification",{"title":7,"searchDepth":122,"depth":122,"links":123},2,[124,126,127,128,129,133],{"depth":125,"text":44},3,{"depth":125,"text":56},{"depth":125,"text":68},{"id":72,"depth":122,"text":75},{"id":78,"depth":122,"text":81,"children":130},[131,132],{"id":84,"depth":125,"text":87},{"id":106,"depth":125,"text":109},{"id":117,"depth":122,"text":120},"markdown","content:blog:2023-12-12-usedcar-miniproject(2).md","content","blog/2023-12-12-usedcar-miniproject(2).md","md",1703393643394]